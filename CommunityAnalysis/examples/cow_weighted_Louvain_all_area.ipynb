{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To use louvain algorithm\n",
    "!pip3 install python-louvain\n",
    "# To use progressbar\n",
    "!pip3 install progressbar2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as m\n",
    "import time \n",
    "from pycowview.data import csv_read_FA\n",
    "from pycowview.manipulate import unique_cows\n",
    "from pycowview.metrics import interaction_time\n",
    "import networkx as nx\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import itertools\n",
    "import os\n",
    "import community\n",
    "from collections import defaultdict,Counter\n",
    "import progressbar\n",
    "import random\n",
    "import itertools \n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from sklearn.metrics.cluster import adjusted_mutual_info_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Weighted version!\n",
    "# This function will get the path of each csv file\n",
    "def findAllFile(base):\n",
    "    for root, ds, fs in os.walk(base):\n",
    "        for f in fs:\n",
    "            if f.endswith('.csv'):\n",
    "                fullname = os.path.join(root, f)\n",
    "                yield fullname\n",
    "\n",
    "# Input is the folders where the time matrix and cowlist are saved\n",
    "# Output is a list which consists of 14 dictionaries\n",
    "# The structure of dictionary:Cowlist,TimeMatrix,AajacencyMatrix_binary,Unweighted_Graph\n",
    "def time_matrix_to_graph(tm_folder,cl_folder):\n",
    "    dict_list = []\n",
    "    i = 0\n",
    "    tmlist = list(findAllFile(tm_folder))\n",
    "    tmlist.sort()\n",
    "    cllist = list(findAllFile(cl_folder))\n",
    "    cllist.sort()\n",
    "    for tm,cl in zip(tmlist,cllist):\n",
    "        # print(tm,cl)\n",
    "        # Get the path of csv\n",
    "        # get cowlist\n",
    "        cowlist = np.loadtxt(cl,delimiter=\",\").astype(int)\n",
    "        # load original time matrix from csv and process it to be an adjacency Matrix\n",
    "        OM = np.asmatrix(np.loadtxt(tm,delimiter=\",\"))\n",
    "        \n",
    "        # Get unweighted adjacency matrix(binary)\n",
    "        # init adjacency matrix\n",
    "        #AM = np.zeros((OM.shape))\n",
    "        # set the threshold to be 30 minutes(1800 seconds)\n",
    "        #epsilon = 1800\n",
    "        # just consider if there is an edge between two cows, the edge is unweighted\n",
    "        #AM[OM >= epsilon] = 1\n",
    "        #AM[OM < epsilon] = 0 \n",
    "        #np.fill_diagonal(AM,0)\n",
    "        # Get graph from AM, no-direct and no-weight graph\n",
    "        #G_AM_temp = nx.from_numpy_matrix(AM,parallel_edges=False,create_using = nx.Graph())\n",
    "        \n",
    "        # Get weighted adjacency matrix\n",
    "        # load original matrix from csv and process it to be an adjacency Matrix\n",
    "        AM = np.zeros((OM.shape))\n",
    "        # set the threshold to be 30 minutes(1800 seconds)\n",
    "        epsilon = 1800\n",
    "        # consider if there is an edge between two cows, the edge is weighted\n",
    "        maxnr=np.amax(OM)\n",
    "        AM=np.where(OM<=epsilon,0,(OM-epsilon)/(maxnr-epsilon))\n",
    "        np.fill_diagonal(AM,0)\n",
    "        # Get graph from AM, no-direct and weighted graph\n",
    "        G_AM_temp = nx.from_numpy_matrix(AM,parallel_edges=False,create_using = nx.Graph())\n",
    "        \n",
    "        # Make sure the order of cowlist is the same as the row name!\n",
    "        print('Shape of matrix:',AM.shape)\n",
    "        print('number of nodes in graph',len(G_AM_temp),'length of cowlist',len(cowlist))\n",
    "        mapping = dict(zip(G_AM_temp, cowlist))\n",
    "        #print(mapping)\n",
    "        # Rename the nodes\n",
    "        G_AM = nx.relabel_nodes(G_AM_temp, mapping)\n",
    "        \n",
    "        # Get the dict of the collection(CL,TM,AM_weighted,Graph)\n",
    "        data_dict = dict(CL=cowlist,TM=OM,AM_weighted=AM,Graph=G_AM)\n",
    "        print('Document No.',i)\n",
    "        print('TM path:',tm,'CL path:',cl)\n",
    "        i = i + 1\n",
    "        dict_list.append(data_dict)\n",
    "\n",
    "    print('The length of the list: ',len(dict_list))\n",
    "    return dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def community_Louvain(i,G):\n",
    "    #print('This is the result of day %d'%(i+1))\n",
    "    \n",
    "    # Nodes whose degree is zero\n",
    "    nodes_removed = [node for node,degree in dict(G.degree()).items() if degree == 0]\n",
    "    # If you want to remove them\n",
    "    #G.remove_nodes_from(nodes_removed)\n",
    "    #print(len(nodes_removed),'nodes whose degree is zero are removed')\n",
    "    \n",
    "    # Louvain algorithm\n",
    "    partition = community.best_partition(G,weight = 'weight',randomize=False)\n",
    "    num_communities = max(partition.values())\n",
    "    \n",
    "    # create a dict object:{community1:[nodelist],community2:[nodelist],......}\n",
    "    # community1:[nodelist] is a tuple\n",
    "    communities_Louvain = defaultdict(list) \n",
    "    for k, v in partition.items():\n",
    "        communities_Louvain[v].append(k)    \n",
    "    np.save('./community/Louvain_weighted/Day_%d_Louvain_weighted_communities.npy'%(i+1), communities_Louvain)\n",
    "    \n",
    "    #read the dict from file\n",
    "    #communities_Louvain = np.load('./community/Louvain/Day_%d_Louvain_Unweighted_communities.npy', allow_pickle='TRUE')\n",
    "    #print(communities_Louvain)\n",
    "\n",
    "    num_communities = max(partition.values())\n",
    "    len_Louvain = len(communities_Louvain)\n",
    "    #print('max No. of community:',num_communities)\n",
    "    #print('num of communities:',len_Louvain)\n",
    "    #print('Modularity:',nx.algorithms.community.quality.modularity(G,communities_Louvain.values()))\n",
    "\n",
    "    # Colormap for plotting\n",
    "    color_Louvain = 0\n",
    "    random.seed(7)\n",
    "    total_colors = list(mpl.colors.get_named_colors_mapping())\n",
    "    total_colors.remove('black')\n",
    "    color_map_Louvain = random.sample(total_colors,len_Louvain)\n",
    "    \n",
    "    '''\n",
    "    # Plot the figure\n",
    "    plt.figure(figsize=(15, 15))  # image size\n",
    "    pos = nx.fruchterman_reingold_layout(G, scale = 1) # position of nodes\n",
    "    degree_dict = dict(G.degree())\n",
    "    nx.draw_networkx(G, pos, node_size=5,width=0.05, alpha=1, with_labels=False)\n",
    "    for community_Louvain in communities_Louvain.items():\n",
    "        \n",
    "        node_list = community_Louvain[1]\n",
    "        edge_list = list(itertools.chain.from_iterable([list(G.edges(node)) for node in node_list]))\n",
    "        label_list = {}\n",
    "        for node in node_list:\n",
    "            #set the node name as the key and the label as its value \n",
    "            label_list[node] = node \n",
    "        community_degree_dict = {key: value for key, value in degree_dict.items() if key in node_list}\n",
    "        node_size_list = [d*20 for d in community_degree_dict.values()]\n",
    "        \n",
    "        nx.draw_networkx_nodes(G, pos , nodelist = node_list, node_size = node_size_list, node_color = color_map_Louvain[color_Louvain],alpha = 0.7)\n",
    "        nx.draw_networkx_edges(G, pos , edgelist = edge_list, edge_color = color_map_Louvain[color_Louvain],alpha = 0.2)\n",
    "        nx.draw_networkx_labels(G, pos, label_list, font_size = 8, font_color = color_map_Louvain[color_Louvain],alpha = 0.7)\n",
    "        color_Louvain += 1\n",
    "    plt.savefig('./community/Louvain_weighted/Day%d_weighted_Community.png'%(i+1))\n",
    "    #plt.show()\n",
    "    '''\n",
    "    return nodes_removed, communities_Louvain, partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_NMI(p1,p2):\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    dict1 = {}\n",
    "    dict2 = {}\n",
    "    key1set = set(sorted(p1))\n",
    "    key2set = set(sorted(p2))\n",
    "    keylist = list(key1set&key2set)\n",
    "    keylist.sort()\n",
    "    #print(len(key1set))\n",
    "    #print(len(key2set))\n",
    "    #print(len(keylist))\n",
    "    i = 0\n",
    "    for key in keylist:\n",
    "        list1.append(p1.get(key,-1))\n",
    "        list2.append(p2.get(key,-1))\n",
    "        dict1[key] = p1.get(key,-1)\n",
    "        dict2[key] = p2.get(key,-1)\n",
    "        #i = i+1\n",
    "        #print(i,key)\n",
    "    #print(list1)\n",
    "    #print(list2)\n",
    "    return normalized_mutual_info_score(list1,list2), adjusted_mutual_info_score(list1,list2), f1_score(list1,list2, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rand_adjacency(day):\n",
    "    # create a random adjacency matrix of a specific day\n",
    "    # compute the density\n",
    "    graph = data_dict_list[day-1].get('Graph')\n",
    "    density = nx.classes.function.density(graph)\n",
    "    # create a basic matrix has the density\n",
    "    AM = data_dict_list[day-1].get('AM_weighted')\n",
    "    AM_rand = np.random.rand(AM.shape[0]*AM.shape[1]).reshape((AM.shape))\n",
    "    AM_temp = np.zeros((AM_rand.shape))\n",
    "    AM_temp[AM_rand <= density] = 1\n",
    "    AM_temp[AM_rand > density] = 0\n",
    "\n",
    "    # unweighted\n",
    "    AM_up = np.triu(AM_temp)\n",
    "    np.fill_diagonal(AM_up,0)\n",
    "    AM_unweighted_rand = AM_up + AM_up.T\n",
    "\n",
    "    # weighted\n",
    "    AM_weighted_up = np.zeros((AM_up.shape))\n",
    "    row,col = np.where(AM_up == 1)\n",
    "    for i,j in zip(row,col):\n",
    "        if AM_up[i][j] == 1:\n",
    "            AM_weighted_up[i][j] = np.random.rand(1)\n",
    "        else:\n",
    "            pass\n",
    "    AM_weighted_rand = AM_weighted_up + AM_weighted_up.T\n",
    "    \n",
    "    return AM_unweighted_rand, AM_weighted_rand "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of matrix: (213, 213)\n",
      "number of nodes in graph 213 length of cowlist 213\n",
      "Document No. 0\n",
      "TM path: ./time_matrix\\Time_FA_20201016T000000UTC.csv CL path: ./cow_list\\Cow_list_20201016T000000UTC.csv\n",
      "Shape of matrix: (212, 212)\n",
      "number of nodes in graph 212 length of cowlist 212\n",
      "Document No. 1\n",
      "TM path: ./time_matrix\\Time_FA_20201017T000000UTC.csv CL path: ./cow_list\\Cow_list_20201017T000000UTC.csv\n",
      "Shape of matrix: (219, 219)\n",
      "number of nodes in graph 219 length of cowlist 219\n",
      "Document No. 2\n",
      "TM path: ./time_matrix\\Time_FA_20201018T000000UTC.csv CL path: ./cow_list\\Cow_list_20201018T000000UTC.csv\n",
      "Shape of matrix: (208, 208)\n",
      "number of nodes in graph 208 length of cowlist 208\n",
      "Document No. 3\n",
      "TM path: ./time_matrix\\Time_FA_20201019T000000UTC.csv CL path: ./cow_list\\Cow_list_20201019T000000UTC.csv\n",
      "Shape of matrix: (209, 209)\n",
      "number of nodes in graph 209 length of cowlist 209\n",
      "Document No. 4\n",
      "TM path: ./time_matrix\\Time_FA_20201020T000000UTC.csv CL path: ./cow_list\\Cow_list_20201020T000000UTC.csv\n",
      "Shape of matrix: (208, 208)\n",
      "number of nodes in graph 208 length of cowlist 208\n",
      "Document No. 5\n",
      "TM path: ./time_matrix\\Time_FA_20201021T000000UTC.csv CL path: ./cow_list\\Cow_list_20201021T000000UTC.csv\n",
      "Shape of matrix: (210, 210)\n",
      "number of nodes in graph 210 length of cowlist 210\n",
      "Document No. 6\n",
      "TM path: ./time_matrix\\Time_FA_20201022T000000UTC.csv CL path: ./cow_list\\Cow_list_20201022T000000UTC.csv\n",
      "Shape of matrix: (210, 210)\n",
      "number of nodes in graph 210 length of cowlist 210\n",
      "Document No. 7\n",
      "TM path: ./time_matrix\\Time_FA_20201023T000000UTC.csv CL path: ./cow_list\\Cow_list_20201023T000000UTC.csv\n",
      "Shape of matrix: (210, 210)\n",
      "number of nodes in graph 210 length of cowlist 210\n",
      "Document No. 8\n",
      "TM path: ./time_matrix\\Time_FA_20201024T000000UTC.csv CL path: ./cow_list\\Cow_list_20201024T000000UTC.csv\n",
      "Shape of matrix: (209, 209)\n",
      "number of nodes in graph 209 length of cowlist 209\n",
      "Document No. 9\n",
      "TM path: ./time_matrix\\Time_FA_20201025T000000UTC.csv CL path: ./cow_list\\Cow_list_20201025T000000UTC.csv\n",
      "Shape of matrix: (205, 205)\n",
      "number of nodes in graph 205 length of cowlist 205\n",
      "Document No. 10\n",
      "TM path: ./time_matrix\\Time_FA_20201026T000000UTC.csv CL path: ./cow_list\\Cow_list_20201026T000000UTC.csv\n",
      "Shape of matrix: (210, 210)\n",
      "number of nodes in graph 210 length of cowlist 210\n",
      "Document No. 11\n",
      "TM path: ./time_matrix\\Time_FA_20201027T000000UTC.csv CL path: ./cow_list\\Cow_list_20201027T000000UTC.csv\n",
      "Shape of matrix: (209, 209)\n",
      "number of nodes in graph 209 length of cowlist 209\n",
      "Document No. 12\n",
      "TM path: ./time_matrix\\Time_FA_20201028T000000UTC.csv CL path: ./cow_list\\Cow_list_20201028T000000UTC.csv\n",
      "Shape of matrix: (205, 205)\n",
      "number of nodes in graph 205 length of cowlist 205\n",
      "Document No. 13\n",
      "TM path: ./time_matrix\\Time_FA_20201029T000000UTC.csv CL path: ./cow_list\\Cow_list_20201029T000000UTC.csv\n",
      "The length of the list:  14\n"
     ]
    }
   ],
   "source": [
    "# This part is used to process the time matrices\n",
    "tm_folder = './time_matrix'\n",
    "cl_folder = './cow_list'\n",
    "data_dict_list = time_matrix_to_graph(tm_folder,cl_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity of weighted adjcaceny matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_k(spectrum, minimum_energy = 0.9):\n",
    "    running_total = 0.0\n",
    "    total = sum(spectrum)\n",
    "    if total == 0.0:\n",
    "        return len(spectrum)\n",
    "    for i in range(len(spectrum)):\n",
    "        running_total += spectrum[i]\n",
    "        if running_total / total >= minimum_energy:\n",
    "            return i + 1\n",
    "    return len(spectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.69912696399258\n",
      "78.69469651391837\n",
      "4.49341784971925\n",
      "1.8695783986913195\n",
      "35.04457880842874\n",
      "1.2454578637871314\n",
      "5.973805070833857\n",
      "29.788064339285434\n",
      "55.516592244954076\n",
      "66.44244241788113\n",
      "150.89953835489598\n",
      "46.6541261406251\n",
      "1.2164612363136527\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(data_dict_list)-1):\n",
    "    graph1 = data_dict_list[i].get('Graph')\n",
    "    graph2 = data_dict_list[i+1].get('Graph')\n",
    "    laplacian1 = nx.spectrum.laplacian_spectrum(graph1)\n",
    "    laplacian2 = nx.spectrum.laplacian_spectrum(graph2)\n",
    "\n",
    "    k1 = select_k(laplacian1)\n",
    "    k2 = select_k(laplacian2)\n",
    "    k = min(k1, k2)\n",
    "\n",
    "    similarity = sum((laplacian1[:k] - laplacian2[:k])**2)\n",
    "    print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (14 of 14) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    }
   ],
   "source": [
    "# Louvain algorithm\n",
    "partition_14days = []\n",
    "Louvain_community_14days = []\n",
    "nodes_removed_14days = []\n",
    "bar = progressbar.ProgressBar()\n",
    "# from 0 to 13\n",
    "for i in bar(range(0,len(data_dict_list))):\n",
    "    nodes_removed_1day, Louvain_community_1day, partition_1day = community_Louvain(i,data_dict_list[i].get('Graph'))\n",
    "    nodes_removed_14days.append(nodes_removed_1day)\n",
    "    Louvain_community_14days.append(Louvain_community_1day)\n",
    "    partition_14days.append(partition_1day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0, 1.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To test our custom functions using karate_club data\n",
    "G1 = nx.karate_club_graph()\n",
    "G2 = nx.karate_club_graph()\n",
    "n1,l1,p1=community_Louvain(1,G1)\n",
    "n2,l2,p2=community_Louvain(1,G2)\n",
    "compute_NMI(p1,p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (13 of 13) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted graph(Louvain)\n",
      "Real Day 1 and Real Day 2 :NMI is (0.16759813447692676, 0.04399274450844319, 0.1301717791111283)\n",
      "Real Day 2 and Real Day 3 :NMI is (0.11373515938702934, -0.002553685759412102, 0.08459330854622636)\n",
      "Real Day 3 and Real Day 4 :NMI is (0.1216408649805718, -0.0015233012720143025, 0.10502459128947593)\n",
      "Real Day 4 and Real Day 5 :NMI is (0.15503870578877993, 0.00017495018003366806, 0.07274456481222105)\n",
      "Real Day 5 and Real Day 6 :NMI is (0.1629188089829455, 0.009438257593828516, 0.05437075269835287)\n",
      "Real Day 6 and Real Day 7 :NMI is (0.17919773324331983, 0.028885450513215387, 0.06579838205329945)\n",
      "Real Day 7 and Real Day 8 :NMI is (0.1735237194029516, 0.0347117623690085, 0.06617987302644973)\n",
      "Real Day 8 and Real Day 9 :NMI is (0.15136977461103673, 0.03719017912849117, 0.10042835321291432)\n",
      "Real Day 9 and Real Day 10 :NMI is (0.1340610112240058, 0.006813156249437027, 0.1040320393996427)\n",
      "Real Day 10 and Real Day 11 :NMI is (0.1855130976519167, 0.0613918260605716, 0.07757822293739819)\n",
      "Real Day 11 and Real Day 12 :NMI is (0.1165777795156541, -0.029531552979828454, 0.07528192751285084)\n",
      "Real Day 12 and Real Day 13 :NMI is (0.13366535884259945, -0.020592421268486052, 0.06272817770021231)\n",
      "Real Day 13 and Real Day 14 :NMI is (0.08513804325752641, -0.041894844957721195, 0.10136746121967798)\n"
     ]
    }
   ],
   "source": [
    "#real day j vs real day j+1\n",
    "bar = progressbar.ProgressBar()\n",
    "print('Weighted graph(Louvain)')\n",
    "for j in bar(range(1,len(data_dict_list))):\n",
    "    print('Real Day %d and Real Day %d :NMI is'%(j,j+1),compute_NMI(partition_14days[j-1],partition_14days[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (1000 of 1000) |####################| Elapsed Time: 0:25:53 Time:  0:25:53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish！\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#random day j vs random day j+1\n",
    "bar = progressbar.ProgressBar()\n",
    "#print('Weighted graph(Louvain)')\n",
    "NMIAVG = np.zeros((1000,13))\n",
    "for k in bar(range(1,1001)):\n",
    "    \n",
    "    for j in range(1,len(data_dict_list)):\n",
    "        # random graph of one day(have the same density) j\n",
    "        uwr1,wr1 = create_rand_adjacency(j)\n",
    "        # Get graph from AM, no-direct and weighted graph\n",
    "        G_AM_temp1 = nx.from_numpy_matrix(wr1,parallel_edges=False,create_using = nx.Graph())\n",
    "        cowlist1 = data_dict_list[j-1].get('CL')\n",
    "        # Make sure the order of cowlist is the same as the row name!\n",
    "        #print('Shape of matrix:',wr.shape)\n",
    "        #print('number of nodes in graph',len(G_AM_temp),'length of cowlist',len(cowlist))\n",
    "        mapping1 = dict(zip(G_AM_temp1, cowlist1))\n",
    "        #print(mapping)\n",
    "        # Rename the nodes\n",
    "        G_AM1 = nx.relabel_nodes(G_AM_temp1, mapping1)\n",
    "        nodes_removed_1day_r1, Louvain_community_1day_r1, partition_1day_r1 = community_Louvain(j-1,G_AM1)\n",
    "\n",
    "        # random graph of one day(have the same density) j\n",
    "        uwr2,wr2 = create_rand_adjacency(j+1)\n",
    "        # Get graph from AM, no-direct and weighted graph\n",
    "        G_AM_temp2 = nx.from_numpy_matrix(wr2,parallel_edges=False,create_using = nx.Graph())\n",
    "        cowlist2 = data_dict_list[j].get('CL')\n",
    "        # Make sure the order of cowlist is the same as the row name!\n",
    "        #print('Shape of matrix:',wr.shape)\n",
    "        #print('number of nodes in graph',len(G_AM_temp),'length of cowlist',len(cowlist))\n",
    "        mapping2 = dict(zip(G_AM_temp2, cowlist2))\n",
    "        #print(mapping)\n",
    "        # Rename the nodes\n",
    "        G_AM2 = nx.relabel_nodes(G_AM_temp2, mapping2)\n",
    "        nodes_removed_1day_r2, Louvain_community_1day_r2, partition_1day_r2 = community_Louvain(j,G_AM2)    \n",
    "        n1,n2,n3 = compute_NMI(partition_1day_r1,partition_1day_r2)\n",
    "        NMIAVG[k-1][j-1] = n1\n",
    "        #print('Random Day %d and Random Day %d :NMI is'%(j,j+1),NMIAVG[k-1][j-1])\n",
    "        \n",
    "    \n",
    "print('Finish！')\n",
    "    #print('----------')\n",
    "    #print('Real Day %d and Real Day %d :NMI is'%(j,j+1),compute_NMI(partition_14days[j-1],partition_14days[j]))\n",
    "    #print('Random Day %d and Random Day %d :NMI is'%(j,j+1),compute_NMI(partition_1day_r1,partition_1day_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two consecutive days & Mean & Variance & Standard deviation\\\\\n",
      "Day 1 and 2: & 0.10262179823394588 & 0.0002910790229389459 & 0.01706103815536868 \\\\\n",
      "Day 2 and 3: & 0.09787934905484656 & 0.00028975116305991256 & 0.017022078693858533 \\\\\n",
      "Day 3 and 4: & 0.10767940766149867 & 0.00030795021095357815 & 0.017548510220345717 \\\\\n",
      "Day 4 and 5: & 0.10641924962003899 & 0.00022439533238946833 & 0.014979830853166145 \\\\\n",
      "Day 5 and 6: & 0.10544164150520333 & 0.00046778747468641246 & 0.02162839510195827 \\\\\n",
      "Day 6 and 7: & 0.10864918915253 & 0.00035731038343726036 & 0.01890265545994161 \\\\\n",
      "Day 7 and 8: & 0.10385102787881653 & 0.00039576101173239425 & 0.01989374302971651 \\\\\n",
      "Day 8 and 9: & 0.12068617048025368 & 0.0003887798949074108 & 0.019717502248190837 \\\\\n",
      "Day 9 and 10: & 0.11090307669255885 & 0.0005351663318646759 & 0.023133662309817612 \\\\\n",
      "Day 10 and 11: & 0.11314365487249993 & 0.00021021583166667423 & 0.01449882173373665 \\\\\n",
      "Day 11 and 12: & 0.12260520686023647 & 0.0002952671871276667 & 0.01718334039491934 \\\\\n",
      "Day 12 and 13: & 0.09926155746058936 & 0.00017663259746699737 & 0.013290319690172896 \\\\\n",
      "Day 13 and 14: & 0.10256332350026123 & 0.0003125559174082161 & 0.01767925104206103 \\\\\n"
     ]
    }
   ],
   "source": [
    "print('Two consecutive days & Mean & Variance & Standard deviation\\\\\\\\')\n",
    "for j in range(1,len(data_dict_list)):\n",
    "    arr = NMIAVG[:][j-1] \n",
    "    # 求均值\n",
    "    arr_mean = np.mean(arr)\n",
    "    # 求方差\n",
    "    arr_var = np.var(arr)\n",
    "    # 求总体标准差\n",
    "    arr_std = np.std(arr)\n",
    "    print('Day %d and %d:'%(j,j+1),'&',arr_mean,'&',arr_var,'&',arr_std,'\\\\\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random list NMI\n",
    "bar = progressbar.ProgressBar()\n",
    "print('Random list NMI')\n",
    "for j in bar(range(1,len(data_dict_list))):\n",
    "    np.random.seed()\n",
    "    list1 = np.random.randint(low = 0, high = 11, size = 210)\n",
    "    np.random.seed()\n",
    "    list2 = np.random.randint(low = 0, high = 11, size = 210)\n",
    "    NMI = normalized_mutual_info_score(list1,list2)\n",
    "    print('NMI of random test %d'%(j),NMI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random graph of day \n",
    "uwr,wr = create_rand_adjacency(6)\n",
    "# Get graph from AM, no-direct and weighted graph\n",
    "G_AM_temp = nx.from_numpy_matrix(wr,parallel_edges=False,create_using = nx.Graph())\n",
    "cowlist = data_dict_list[5].get('CL')\n",
    "# Make sure the order of cowlist is the same as the row name!\n",
    "print('Shape of matrix:',wr.shape)\n",
    "print('number of nodes in graph',len(G_AM_temp),'length of cowlist',len(cowlist))\n",
    "mapping = dict(zip(G_AM_temp, cowlist))\n",
    "#print(mapping)\n",
    "# Rename the nodes\n",
    "G_AM = nx.relabel_nodes(G_AM_temp, mapping)\n",
    "nodes_removed_1day_r, Louvain_community_1day_r, partition_1day_r = community_Louvain(5,G_AM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The NMI of real day1 and real day2\n",
    "list1 = []\n",
    "list2 = []\n",
    "key1set = set(sorted(partition_14days[0]))\n",
    "key2set = set(sorted(partition_14days[1]))\n",
    "keylist = list(key1set&key2set)\n",
    "print(len(key1set))\n",
    "print(len(key2set))\n",
    "print(len(keylist))\n",
    "keylist.sort()\n",
    "i = 0\n",
    "for key in keylist:\n",
    "    list1.append(partition_14days[0].get(key,-1))\n",
    "    list2.append(partition_14days[1].get(key,-1))\n",
    "    #i = i+1\n",
    "    #print(i,key)\n",
    "#print(list1)\n",
    "#print(list2)\n",
    "normalized_mutual_info_score(list1,list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The NMI of real day1 and random day1\n",
    "list1 = []\n",
    "list2 = []\n",
    "key1set = set(sorted(partition_14days[0]))\n",
    "key2set = set(sorted(partition_1day_r))\n",
    "keylist = list(key1set&key2set)\n",
    "print(len(key1set))\n",
    "print(len(key2set))\n",
    "print(len(keylist))\n",
    "keylist.sort()\n",
    "i = 0\n",
    "for key in keylist:\n",
    "    list1.append(partition_14days[0].get(key,-1))\n",
    "    list2.append(partition_1day_r.get(key,-1))\n",
    "    #i = i+1\n",
    "    #print(i,key)\n",
    "#print(list1)\n",
    "#print(list2)\n",
    "normalized_mutual_info_score(list1,list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The NMI of real day2 and random day1\n",
    "list1 = []\n",
    "list2 = []\n",
    "key1set = set(sorted(partition_14days[1]))\n",
    "key2set = set(sorted(partition_1day_r))\n",
    "keylist = list(key1set&key2set)\n",
    "print(len(key1set))\n",
    "print(len(key2set))\n",
    "print(len(keylist))\n",
    "keylist.sort()\n",
    "i = 0\n",
    "for key in keylist:\n",
    "    list1.append(partition_14days[1].get(key,-1))\n",
    "    list2.append(partition_1day_r.get(key,-1))\n",
    "    #i = i+1\n",
    "    #print(i,key)\n",
    "#print(list1)\n",
    "#print(list2)\n",
    "normalized_mutual_info_score(list1,list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random graph of day 13\n",
    "uwr13,wr13 = create_rand_adjacency(13)\n",
    "# Get graph from AM, no-direct and weighted graph\n",
    "G_AM_temp = nx.from_numpy_matrix(wr13,parallel_edges=False,create_using = nx.Graph())\n",
    "cowlist = data_dict_list[12].get('CL')\n",
    "# Make sure the order of cowlist is the same as the row name!\n",
    "print('Shape of matrix:',wr13.shape)\n",
    "print('number of nodes in graph',len(G_AM_temp),'length of cowlist',len(cowlist))\n",
    "mapping = dict(zip(G_AM_temp, cowlist))\n",
    "#print(mapping)\n",
    "# Rename the nodes\n",
    "G_AM = nx.relabel_nodes(G_AM_temp, mapping)\n",
    "nodes_removed_1day_r, Louvain_community_1day_r, partition_1day_r = community_Louvain(0,G_AM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The NMI of real day13 and random day13\n",
    "list1 = []\n",
    "list2 = []\n",
    "key1set = set(sorted(partition_14days[12]))\n",
    "key2set = set(sorted(partition_1day_r))\n",
    "keylist = list(key1set&key2set)\n",
    "print(len(key1set))\n",
    "print(len(key2set))\n",
    "print(len(keylist))\n",
    "keylist.sort()\n",
    "i = 0\n",
    "for key in keylist:\n",
    "    list1.append(partition_14days[12].get(key,-1))\n",
    "    list2.append(partition_1day_r.get(key,-1))\n",
    "    #i = i+1\n",
    "    #print(i,key)\n",
    "#print(list1)\n",
    "#print(list2)\n",
    "normalized_mutual_info_score(list1,list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The NMI of real day14 and random day13\n",
    "list1 = []\n",
    "list2 = []\n",
    "key1set = set(sorted(partition_14days[13]))\n",
    "key2set = set(sorted(partition_1day_r))\n",
    "keylist = list(key1set&key2set)\n",
    "print(len(key1set))\n",
    "print(len(key2set))\n",
    "print(len(keylist))\n",
    "keylist.sort()\n",
    "i = 0\n",
    "for key in keylist:\n",
    "    list1.append(partition_14days[13].get(key,-1))\n",
    "    list2.append(partition_1day_r.get(key,-1))\n",
    "    #i = i+1\n",
    "    #print(i,key)\n",
    "#print(list1)\n",
    "#print(list2)\n",
    "normalized_mutual_info_score(list1,list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The NMI of real day14 and real day13\n",
    "list1 = []\n",
    "list2 = []\n",
    "key1set = set(sorted(partition_14days[13]))\n",
    "key2set = set(sorted(partition_14days[12]))\n",
    "keylist = list(key1set&key2set)\n",
    "print(len(key1set))\n",
    "print(len(key2set))\n",
    "print(len(keylist))\n",
    "keylist.sort()\n",
    "i = 0\n",
    "for key in keylist:\n",
    "    list1.append(partition_14days[13].get(key,-1))\n",
    "    list2.append(partition_14days[12].get(key,-1))\n",
    "    #i = i+1\n",
    "    #print(i,key)\n",
    "#print(list1)\n",
    "#print(list2)\n",
    "normalized_mutual_info_score(list1,list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check the first day community\n",
    "for c,n in Louvain_community_14days[0].items():\n",
    "    n.sort()\n",
    "    print('community',c)\n",
    "    print('number of nodes in community',len(n))\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for c,n in Louvain_community_14days[1].items():\n",
    "    n.sort()\n",
    "    print('community',c)\n",
    "    print('number of nodes in community',len(n))\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def compute_NMI(day1,day2):\n",
    "    list1 = list(partition_14days[day1-1].values())\n",
    "    list2 = list(partition_14days[day2-1].values())\n",
    "    if len(list1)<len(list2):\n",
    "        rand = np.random.randint(low = 0, high = max(list1)+1, size = len(list2)-len(list1))\n",
    "        list1.extend(rand)\n",
    "    elif len(list2)<len(list1):\n",
    "        rand = np.random.randint(low = 0, high = max(list2)+1, size = len(list1)-len(list2))\n",
    "        list2.extend(rand)\n",
    "    else:\n",
    "        pass\n",
    "    print(len(list1),len(list2))\n",
    "    return normalized_mutual_info_score(list1,list2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Draft\n",
    "rand = np.random.randint(low = 0, high = max(partition_14days[0].values())+1, size = 1)\n",
    "print(partition_14days[0].get(999,rand[0]))\n",
    "list1=[]\n",
    "list2=[]\n",
    "key1set = set(sorted(partition_14days[0]))\n",
    "key2set = set(sorted(partition_14days[1]))\n",
    "keylist = list(key1set&key2set)\n",
    "keylist.sort()\n",
    "i = 0\n",
    "for key in keylist:\n",
    "    list1.append(partition_14days[0].get(key,-1))\n",
    "    list2.append(partition_14days[1].get(key,-1))\n",
    "    #i = i+1\n",
    "    #print(i,key)\n",
    "normalized_mutual_info_score(list1,list2)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
